#this is the params file for training a model for HB phrase detection. 
#second version of the model

Global:
  cache_root: C:/Apps/INSTINCT/Cache
  #cache_root: //161.55.120.117/NMML_AcousticsData/Working_Folders/INSTINCT_cache/Cache
  #SF_raw: //161.55.120.117/NMML_AcousticsData/Audio_Data/Waves  #switch back to this after making new matlab decimation method
  #SF_foc: //161.55.120.117/NMML_AcousticsData/Audio_Data/DecimatedWaves
  SF_raw: //161.55.120.117/NMML_AcousticsData/Audio_Data
  SF_foc: //161.55.120.117/NMML_AcousticsData/Audio_Data/DecimatedWaves
  #True of False: indicates if job will have an output (False) or just populates Cache (True). Luigi style 'wrapper'.
  Wrapper: False
  parameters:
    freq_start: 40
    freq_size: 300
    #tilepix_h: 300
    native_height: 151
    npps: 31
    signal_codes: RW
    #msp_train: 15
    msp_train: 20
    msp_inf: 5
    split_prot: within_file
    inf_batch_size: 175
    time_expand_spec: 2
    model_window_native: 224
Job:
  ModelEval_NN:
    parameters:
      methodID: simple-eval
      methodvers: v1-1
      gt_depth: [signal_codes]
    arguments: 
      hard_rerun: y
    descriptors:
      runtype: lib
      language: Python
  DLmodel*:
    parameters:
      methodID: train-win-slide-dl
      methodvers: v1-4
      gt_depth: [signal_codes]
      model_name: EffecientNetB0
      native_height: [native_height]
      native_pix_per_sec: [npps]
      perc_fp: 0.97
      perc_tp: 0.03
      #in native pix:
      stride_pix: [msp_inf]
      view_plots: n
      #stride_pix: 1
      #what to multiply npps by to get to model resolution
      win_factor_f: 1.4834
      win_factor_t: [time_expand_spec]
      #in pixels
      win_height: [model_window_native]
      win_length: 248
    arguments: 
      batch_size: [inf_batch_size]
      hard_rerun: y
    descriptors:
      runtype: lib
      language: Python
      venv: Conda
      venv_name: tf-gpu3
  FormatFG:
    parameters:
      decimate_data: y
      methodID: dbuddy-pull-FG-wname
      methodvers: v1-0
      methodID2m: matlabdecimate
      methodvers2m: V1s0
      #target_samp_rate: 4096
      target_samp_rate: 1024
      file_groupID:
        #- NOPP6_EST_20090328_files_All.csv
        #- NOPP6_EST_20090329_files_All.csv
        #- NOPP6_EST_20090330_files_All.csv
        #- NOPP6_EST_20090331_files_All.csv
        - NOPP6_EST_20090401_files_All.csv
        - NOPP6_EST_20090402_files_All.csv
        - NOPP6_EST_20090403_files_All.csv
    arguments:
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
      runtype2m: bin
      language2m: MATLAB
  TrainModel_paramset:
    FormatFG:
      parameters:
        decimate_data: y
        methodID: dbuddy-pull-FG-wname
        #methodID: dbuddy-pull-FG
        #methodID: dbuddy-pull-FG-ord
        methodvers: v1-0
        methodID2m: matlabdecimate
        methodvers2m: V1s0
        #target_samp_rate: 4096
        target_samp_rate: 1024
        file_groupID:
          - NOPP6_EST_20090328_files_All.csv
          - NOPP6_EST_20090329_files_All.csv
          - NOPP6_EST_20090330_files_All.csv
          - NOPP6_EST_20090331_files_All.csv
          #- NOPP6_EST_20090401_files_All.csv
          #- NOPP6_EST_20090402_files_All.csv
          #- NOPP6_EST_20090403_files_All.csv
      arguments:
        hard_rerun: n
      descriptors:
        runtype: lib
        language: R
        runtype2m: bin
        language2m: MATLAB
    seperate_ds_train:
      SplitTensor:
        parameters:
          methodID: tens-simple-split
          methodvers: v1-1
          native_pix_per_sec: [npps]
          seed_val: 1
          #by_file or within_file
          split_protocol: [split_prot]
          test_split: n
          #do not break into test splits
          train_test_split: 1.0
          #train_test_split: 0.80
          #of the test in previous, what is the split between train and val
          train_val_split: 0.75
          #or per_file. by-file smoother, per_file more label effecient
          use_seed: y    
        arguments:
          hard_rerun: n
        descriptors:
          runtype: lib
          language: R
    test1:
      DLmodel*:
        parameters:
          methodID: train-win-slide-dl
          methodvers: v1-4
          brightness_high: 0.25
          brightness_low: 0.55
          contrast_high: 1
          contrast_low: 1
          gt_depth: [signal_codes]
          learn_rate: 0.001
          model_name: EffecientNetB0
          native_height: [native_height]
          native_pix_per_sec: [npps]
          #perc_fp: 0.99
          #perc_tp: 0.01
          perc_fp: 0.97
          perc_tp: 0.03
          #in native pix:
          stride_pix: [msp_train]
          #including this has the effect of stride_pix_inf being a parameter which will redo training... 
          stride_pix_inf: [msp_inf]
          view_plots: n
          #stride_pix: 1
          #this gets to exact model height
          win_factor_f: 1.4834
          #what to multiply npps by to get to model resolution
          #win_factor_t: 3
          win_factor_t: [time_expand_spec]
          #in pixels
          win_height: [model_window_native]
          #win_length: 279
          win_length: 248
        arguments: 
          batch_size: 175
          batch_size_inf: [inf_batch_size]
          epoch: 15
          #epoch: 1
          hard_rerun: n
        descriptors:
          runtype: lib
          language: Python
          venv: Conda
          venv_name: tf-gpu3
      ScoresToDETx:
        parameters:
          #group output scores by # of pixels(can be different to original step to 'smooth')
          methodID: moving-smooth-nocorrect
          methodvers: v1-0
          freq_low: [freq_start]
          freq_size: [freq_size]
          group_pixels: 20
          mod_size_l: [model_window_native]
          native_pix_per_sec: [npps]
          smooth_method: mean
          split_protocol: [split_prot]
          stride_pix: [msp_train]
          time_expand: [time_expand_spec]
        arguments:
          hard_rerun: n
        descriptors:
          runtype: lib
          language: R
  GenBigSpec:
    parameters:
      methodID: con_bright_no_rep
      methodvers: v1-3
      crop_freq: y
      crop_freq_size: [freq_size]
      crop_freq_start: [freq_start]
      native_height: [native_height]
      native_pix_per_sec: [npps]
      window_length: 512
    arguments:
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  LabelTensor:
    parameters:
      methodID: tens-simple-label
      methodvers: v1-3
      #1 if only on time, 2 if time/frequency
      dimensions: 2
      #reduce_factor is the factor by which to divide spec dimensions (lower resolution than spec) 
      freq_size: [freq_size]
      freq_start: [freq_start]
      native_height: [native_height]
      native_pix_per_sec: [npps]
    arguments:
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  SplitTensor:
    parameters:
      methodID: tens-simple-split
      methodvers: v1-1
      native_pix_per_sec: [npps]
      seed_val: 1
      #by_file or within_file
      split_protocol: within_file
      test_split: n
      train_test_split: 0.80
      #of the test in previous, what is the split between train and val
      train_val_split: 0.75
      #or per_file. by-file smoother, per_file more label effecient
      use_seed: y    
    arguments:
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  seperate_ds_test:
    SplitTensor:
      parameters:
        methodID: tens-simple-split
        methodvers: v1-1
        native_pix_per_sec: [npps]
        seed_val: 1
        #by_file or within_file
        split_protocol: within_file
        test_split: n
        train_test_split: 0
        #of the test in previous, what is the split between train and val
        train_val_split: 0.75
        #or per_file. by-file smoother, per_file more label effecient
        use_seed: y    
      arguments:
        hard_rerun: n
      descriptors:
        runtype: lib
        language: R
  FormatGT:
    parameters: 
      methodID: R-pull-dbuddy-anyparam
      methodvers: v1-3
      UseFG: y
      Analysis_ID: 10
      #multiple can be specified with "," (no space) 
      SignalCode: [signal_codes]
    arguments: 
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  RavenViewDETx:
    parameters: 
      methodID: rv-simple-w-metadata
      methodvers: v1-8
    arguments:
    #previously called RavenFill
    #this shuold really be a parameter, not an argument
    #I should change this to y/n to be more consistent with other parameters
      fg_fill: T
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  RavenToDETx:
    parameters: 
      methodID: rd-simple-w-metadata
      methodvers: v1-5
    descriptors:
      runtype: lib
      language: R
  AssignLabels:
    parameters: 
      methodID: labels-w-iou-simple
      methodvers: v1-4
      iou_thresh: 0.01
      write_GT: y
    arguments: 
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  PerfEval2DL:
    parameters:
      methodID: pe2dl-simple
      methodvers: v1-1
      cexmod: 2
    arguments: 
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  EditRAVENx:
    #this process always has an instructions parameter. changing these will change hash
    parameters: 
      instructions:
        > 
        > INSTRUCTIONS: 
        >
        > Open up a Raven Pro 1.5 window. Holding the control key, drag and drop the file into the Raven window.        
        > Review the outputs and populate label column. Allowable labels are y/m/n (yes, maybe, or no).  
        > Comments can be made and will be retained in the database. Adding, deleting, or modifying timestamps or frequency of
        > detections is forbidden by protocol. 
        > 
        > To revise your review, do not run this task again if it has been published! This will result in duplicates in the database. 
        > Instead, use the EditGTpublish pipeline. 
        >
        > If you are rerunning this process, there may be a previously edited file you are free to override or retain
    arguments: 
      #this dicates the unique iteration that will be read. Changing this value allows for redoing processes. 
      #rerun_key: 0
      hard_rerun: n
    descriptors:
      runtype: no_method
  CompareAndPublishDets:
    parameters:
      methodID: dbuddy-compare-publish
      methodvers: v1-2
    arguments: 
      hard_rerun: n
    descriptors:
      language: R
      runtype: lib
  ScoresToDETx:
    parameters:
      #group output scores by # of pixels(can be different to original step to 'smooth')
      methodID: moving-smooth-nocorrect
      methodvers: v1-0
      freq_low: [freq_start]
      freq_size: [freq_size]
      group_pixels: 20
      mod_size_l: [model_window_native]
      native_pix_per_sec: [npps]
      smooth_method: mean
      split_protocol: [split_prot]
      stride_pix: [msp_inf]
      time_expand: [time_expand_spec]
    arguments:
      hard_rerun: n
    descriptors:
      runtype: lib
      language: R
  ApplyCutoff:
    parameters:
      cutoff: 0.80
    descriptors:
      runtype: no_method
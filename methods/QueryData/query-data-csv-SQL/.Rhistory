data<-data[-which(matches),]
}
}
}
data
#cant do it this way unfortunately, with the internal quotes. maybe can find a better way eventually..
args="C:/Apps/INSTINCT/Data/FileGroups //161.55.120.117/NMML_AcousticsData/Audio_Data NewTestFG.csv //nmfs/akc-nmml/CAEP/Acoustics/ANALYSIS/RWupcallYeses4Dan.csv AL16_AU_BS01_files_All.csv,AL16_AU_BS03_files_59-114.csv 6 1 query-random-v1-0"
args<-strsplit(args,split=" ")[[1]]
resultPath<- args[1]
SfRoot<- args[2]
fileName <- args[3]
datapath <- args[4]
Exclude <-args[5] #vector of FG to exclude from sample
Pulls<- as.numeric(args[6])
RandSeed<- as.numeric(args[7])
#make random pulls consistent depending on seed set
set.seed(RandSeed)
source(paste("C:/Apps/INSTINCT/lib/supporting/instinct_fxns.R",sep=""))
data<-read.csv(datapath)
#mandate column names to fit standard (column names changed on Cath end)
colnames(data)[1:7]<-c("Wavefile","StartSecInWav","EndSecInWav","MooringSite","MooringDeployID","StartFieldTimeUTC","EndFieldTimeUTC")
data<-dataFormat(data)
#remove any NA rows
if(any(is.na(data$dur))){
data<-data[-which(is.na(data$dur)),]
}
#load in other FG, and remove them from data.
if(Exclude!="None"){
Exclude<-strsplit(Exclude,split=",")[[1]]
for(n in 1:length(Exclude)){
#load in FG
FG<-read.csv(paste(resultPath,"/",Exclude[n],sep=""))
matches <-paste(getFileName(data$Wavefile),data$StartSecInWav,data$EndSecInWav) %in% paste(FG$FileName,FG$SegStart,FG$SegStart+FG$SegDur)
if(any(matches)){
data<-data[-which(matches),]
}
}
}
cycleVar<-1
data<-foreach(i=1:length(unique(data$MooringDeployID))) %do% {
DatMoor<-data[which(data$MooringDeployID==unique(data$MooringDeployID)[i]),]
DatMoor<-DatMoor[order(DatMoor$StartDateTime),]
DatMoor$Cycle<-0
for(n in 1:nrow(DatMoor)){
DatMoor$Cycle[n]<-cycleVar
if(DatMoor$EndFieldTimeUTC[n]!=DatMoor$StartFieldTimeUTC[n+1]&n!=nrow(DatMoor)){
cycleVar<-cycleVar+1
}
}
return(DatMoor)
}
data<-do.call("rbind",data)
cyclesPull<-sample(data$Cycle,Pulls)
index<-which(data$Cycle %in% cyclesPull)
datasub<-data[sample(index,length(index)),] #randomize index, so when you sort by cycle you don't pure random order
datasub<-datasub[order(sort(datasub$Cycle)),]
View(datasub)
datasub
datasub<-datasub[order(datasub$Cycle),]
datasub
datasub<-data[sample(index,length(index)),] #randomize index, so when you sort by cycle you don't pure random order
datasub
unique(datasub$Cycle)
which(datasub$Cycle==unique(datasub$Cycle))
unique(datasub$Cycle)==datasub$Cycle
which(unique(datasub$Cycle)==datasub$Cycle)
datasub<-data[sample(index,length(index)),] #randomize index, so when you sort by cycle you don't pure random order
datasub
cbind(unique(datasub$Cycle),1:length(unique(datasub$Cycle)))
orders[which(orders[,1]==datasub$Cycle)2]
orders[which(orders[,1]==datasub$Cycle),2]
orders<-cbind(unique(datasub$Cycle),1:length(unique(datasub$Cycle)))
orders[which(orders[,1]==datasub$Cycle),2]
orders[,1]
datasub$Cycle
orders[,1]==datasub$Cycle
orders[datasub$Cycle,]
orders[orders[1,]==datasub$Cycle,]
orders
orders[,1]
datasub$Cycle
match(datasub$Cycle, orders[,1])
datasub$Cycle<-match(datasub$Cycle, orders[,1])
datasub<-datasub[order(datasub$Cycle),]
View(datasub)
datasub<-datasub[order(datasub$Cycle,datasub$StartDateTime),]
View(datasub)
#now convert it to FG format
sf<-getFileName(datasub$Wavefile)
sfdt<-vector(length=length(sf))
#insert a slash
for(n in 1:length(sf)){
lenN<-nchar(sf[n])
sfdt[n]<-substr(sf[n],lenN-16,lenN-4)
#sf[n]<-paste(substr(sf[n],1,lenN-17),"-",sfdt[n],sep="")
}
year<-paste("20",substr(sfdt,1,2),sep="")
month<-substr(sfdt,3,4)
#assemble fg:
out<-data.frame(sf,paste("/",datasub$MooringDeployID,"/",month,"_",year,"/",sep=""),sfdt,0,datasub$MooringDeployID,datasub$StartSecInWav,datasub$EndSecInWav-datasub$StartSecInWav,datasub$MooringSite)
colnames(out)<-c("FileName","FullPath","StartTime","Duration","Deployment","SegStart","SegDur","SiteID")
pathsave<-""
#find the file durations
for(i in 1:nrow(out)){
path = paste(SfRoot,"/Waves",out[i,"FullPath"],out[i,"FileName"],sep="")
if(path!=pathsave){
info<-readWave2(path,header = TRUE)
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}else{
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}
}
out
#cant do it this way unfortunately, with the internal quotes. maybe can find a better way eventually..
args="C:/Apps/INSTINCT/Data/FileGroups //161.55.120.117/NMML_AcousticsData/Audio_Data NewTestFG.csv //nmfs/akc-nmml/CAEP/Acoustics/ANALYSIS/RWupyeses_1.csv AL16_AU_BS01_files_All.csv,AL16_AU_BS03_files_59-114.csv 6 1 query-random-v1-0"
args<-strsplit(args,split=" ")[[1]]
resultPath<- args[1]
SfRoot<- args[2]
fileName <- args[3]
datapath <- args[4]
Exclude <-args[5] #vector of FG to exclude from sample
Pulls<- as.numeric(args[6])
RandSeed<- as.numeric(args[7])
#make random pulls consistent depending on seed set
set.seed(RandSeed)
source(paste("C:/Apps/INSTINCT/lib/supporting/instinct_fxns.R",sep=""))
data<-read.csv(datapath)
#mandate column names to fit standard (column names changed on Cath end)
colnames(data)[1:7]<-c("Wavefile","StartSecInWav","EndSecInWav","MooringSite","MooringDeployID","StartFieldTimeUTC","EndFieldTimeUTC")
data<-dataFormat(data)
#remove any NA rows
if(any(is.na(data$dur))){
data<-data[-which(is.na(data$dur)),]
}
#load in other FG, and remove them from data.
if(Exclude!="None"){
Exclude<-strsplit(Exclude,split=",")[[1]]
for(n in 1:length(Exclude)){
#load in FG
FG<-read.csv(paste(resultPath,"/",Exclude[n],sep=""))
matches <-paste(getFileName(data$Wavefile),data$StartSecInWav,data$EndSecInWav) %in% paste(FG$FileName,FG$SegStart,FG$SegStart+FG$SegDur)
if(any(matches)){
data<-data[-which(matches),]
}
}
}
cycleVar<-1
data<-foreach(i=1:length(unique(data$MooringDeployID))) %do% {
DatMoor<-data[which(data$MooringDeployID==unique(data$MooringDeployID)[i]),]
DatMoor<-DatMoor[order(DatMoor$StartDateTime),]
DatMoor$Cycle<-0
for(n in 1:nrow(DatMoor)){
DatMoor$Cycle[n]<-cycleVar
if(DatMoor$EndFieldTimeUTC[n]!=DatMoor$StartFieldTimeUTC[n+1]&n!=nrow(DatMoor)){
cycleVar<-cycleVar+1
}
}
return(DatMoor)
}
data<-do.call("rbind",data)
cyclesPull<-sample(data$Cycle,Pulls)
index<-which(data$Cycle %in% cyclesPull)
datasub<-data[sample(index,length(index)),] #randomize index, so when you sort by cycle you don't pure random order
orders<-cbind(unique(datasub$Cycle),1:length(unique(datasub$Cycle)))
datasub$Cycle<-match(datasub$Cycle, orders[,1])
datasub<-datasub[order(datasub$Cycle,datasub$StartDateTime),]
#now convert it to FG format
sf<-getFileName(datasub$Wavefile)
sfdt<-vector(length=length(sf))
#insert a slash
for(n in 1:length(sf)){
lenN<-nchar(sf[n])
sfdt[n]<-substr(sf[n],lenN-16,lenN-4)
#sf[n]<-paste(substr(sf[n],1,lenN-17),"-",sfdt[n],sep="")
}
year<-paste("20",substr(sfdt,1,2),sep="")
month<-substr(sfdt,3,4)
#assemble fg:
out<-data.frame(sf,paste("/",datasub$MooringDeployID,"/",month,"_",year,"/",sep=""),sfdt,0,datasub$MooringDeployID,datasub$StartSecInWav,datasub$EndSecInWav-datasub$StartSecInWav,datasub$MooringSite)
colnames(out)<-c("FileName","FullPath","StartTime","Duration","Deployment","SegStart","SegDur","SiteID")
pathsave<-""
#find the file durations
for(i in 1:nrow(out)){
path = paste(SfRoot,"/Waves",out[i,"FullPath"],out[i,"FileName"],sep="")
if(path!=pathsave){
info<-readWave2(path,header = TRUE)
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}else{
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}
}
#Do not allow overrides! Test to see if file is present, and only print if not. If it is, spit an error.
filePath<-paste(resultPath,"/",fileName,sep="")
file.exists(filePath)
filePath
write.csv(out,filePath,row.names = FALSE)
#cant do it this way unfortunately, with the internal quotes. maybe can find a better way eventually..
args="C:/Apps/INSTINCT/Data/FileGroups //161.55.120.117/NMML_AcousticsData/Audio_Data NewFGtest.csv //nmfs/akc-nmml/CAEP/Acoustics/ANALYSIS/RWupyeses_1.csv AL16_AU_BS01_files_All.csv,AL16_AU_BS03_files_59-114.csv 6 1 query-random-v1-0"
args<-strsplit(args,split=" ")[[1]]
resultPath<- args[1]
SfRoot<- args[2]
fileName <- args[3]
datapath <- args[4]
Exclude <-args[5] #vector of FG to exclude from sample
Pulls<- as.numeric(args[6])
RandSeed<- as.numeric(args[7])
#make random pulls consistent depending on seed set
set.seed(RandSeed)
source(paste("C:/Apps/INSTINCT/lib/supporting/instinct_fxns.R",sep=""))
data<-read.csv(datapath)
#mandate column names to fit standard (column names changed on Cath end)
colnames(data)[1:7]<-c("Wavefile","StartSecInWav","EndSecInWav","MooringSite","MooringDeployID","StartFieldTimeUTC","EndFieldTimeUTC")
data<-dataFormat(data)
#remove any NA rows
if(any(is.na(data$dur))){
data<-data[-which(is.na(data$dur)),]
}
#load in other FG, and remove them from data.
if(Exclude!="None"){
Exclude<-strsplit(Exclude,split=",")[[1]]
for(n in 1:length(Exclude)){
#load in FG
FG<-read.csv(paste(resultPath,"/",Exclude[n],sep=""))
matches <-paste(getFileName(data$Wavefile),data$StartSecInWav,data$EndSecInWav) %in% paste(FG$FileName,FG$SegStart,FG$SegStart+FG$SegDur)
if(any(matches)){
data<-data[-which(matches),]
}
}
}
cycleVar<-1
data<-foreach(i=1:length(unique(data$MooringDeployID))) %do% {
DatMoor<-data[which(data$MooringDeployID==unique(data$MooringDeployID)[i]),]
DatMoor<-DatMoor[order(DatMoor$StartDateTime),]
DatMoor$Cycle<-0
for(n in 1:nrow(DatMoor)){
DatMoor$Cycle[n]<-cycleVar
if(DatMoor$EndFieldTimeUTC[n]!=DatMoor$StartFieldTimeUTC[n+1]&n!=nrow(DatMoor)){
cycleVar<-cycleVar+1
}
}
return(DatMoor)
}
data<-do.call("rbind",data)
cyclesPull<-sample(data$Cycle,Pulls)
index<-which(data$Cycle %in% cyclesPull)
datasub<-data[sample(index,length(index)),] #randomize index, so when you sort by cycle you don't pure random order
orders<-cbind(unique(datasub$Cycle),1:length(unique(datasub$Cycle)))
datasub$Cycle<-match(datasub$Cycle, orders[,1])
datasub<-datasub[order(datasub$Cycle,datasub$StartDateTime),]
#now convert it to FG format
sf<-getFileName(datasub$Wavefile)
sfdt<-vector(length=length(sf))
#insert a slash
for(n in 1:length(sf)){
lenN<-nchar(sf[n])
sfdt[n]<-substr(sf[n],lenN-16,lenN-4)
#sf[n]<-paste(substr(sf[n],1,lenN-17),"-",sfdt[n],sep="")
}
year<-paste("20",substr(sfdt,1,2),sep="")
month<-substr(sfdt,3,4)
#assemble fg:
out<-data.frame(sf,paste("/",datasub$MooringDeployID,"/",month,"_",year,"/",sep=""),sfdt,0,datasub$MooringDeployID,datasub$StartSecInWav,datasub$EndSecInWav-datasub$StartSecInWav,datasub$MooringSite)
colnames(out)<-c("FileName","FullPath","StartTime","Duration","Deployment","SegStart","SegDur","SiteID")
pathsave<-""
#find the file durations
for(i in 1:nrow(out)){
path = paste(SfRoot,"/Waves",out[i,"FullPath"],out[i,"FileName"],sep="")
if(path!=pathsave){
info<-readWave2(path,header = TRUE)
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}else{
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}
}
#Do not allow overrides! Test to see if file is present, and only print if not. If it is, spit an error.
filePath<-paste(resultPath,"/",fileName,sep="")
if(file.exists(filePath)){
stop("Cannot overwrite existing FG of same name! Stopping...")
}else{
write.csv(out,filePath,row.names = FALSE)
}
statement <- "StartDateTime > '2016-10-04 21:13:45' AND StartDateTime < '2017-10-10 21:13:45' AND MooringSite = 'BS01' LIMIT 150"
#cant do it this way unfortunately, with the internal quotes. maybe can find a better way eventually..
args="C:/Apps/INSTINCT/Data/FileGroups //161.55.120.117/NMML_AcousticsData/Audio_Data NewFGtest.csv //nmfs/akc-nmml/CAEP/Acoustics/ANALYSIS/RWupyeses_1.csv AL16_AU_BS01_files_All.csv,AL16_AU_BS03_files_59-114.csv 6 1 query-random-v1-0"
args<-strsplit(args,split=" ")[[1]]
resultPath<- args[1]
SfRoot<- args[2]
fileName <- args[3]
datapath <- args[4]
Exclude <-args[5] #vector of FG to exclude from sample
Pulls<- as.numeric(args[6])
RandSeed<- as.numeric(args[7])
#make random pulls consistent depending on seed set
set.seed(RandSeed)
source(paste("C:/Apps/INSTINCT/lib/supporting/instinct_fxns.R",sep=""))
data<-read.csv(datapath)
data$Wavefile<-as.character(data$Wavefile)
#mandate column names to fit standard (column names changed on Cath end)
colnames(data)[1:7]<-c("Wavefile","StartSecInWav","EndSecInWav","MooringSite","MooringDeployID","StartFieldTimeUTC","EndFieldTimeUTC")
data<-dataFormat(data)
#remove any NA rows
if(any(is.na(data$dur))){
data<-data[-which(is.na(data$dur)),]
}
#load in other FG, and remove them from data.
if(Exclude!="None"){
Exclude<-strsplit(Exclude,split=",")[[1]]
for(n in 1:length(Exclude)){
#load in FG
FG<-read.csv(paste(resultPath,"/",Exclude[n],sep=""))
matches <-paste(getFileName(data$Wavefile),data$StartSecInWav,data$EndSecInWav) %in% paste(FG$FileName,FG$SegStart,FG$SegStart+FG$SegDur)
if(any(matches)){
data<-data[-which(matches),]
}
}
}
cycleVar<-1
data<-foreach(i=1:length(unique(data$MooringDeployID))) %do% {
DatMoor<-data[which(data$MooringDeployID==unique(data$MooringDeployID)[i]),]
DatMoor<-DatMoor[order(DatMoor$StartDateTime),]
DatMoor$Cycle<-0
for(n in 1:nrow(DatMoor)){
DatMoor$Cycle[n]<-cycleVar
if(DatMoor$EndFieldTimeUTC[n]!=DatMoor$StartFieldTimeUTC[n+1]&n!=nrow(DatMoor)){
cycleVar<-cycleVar+1
}
}
return(DatMoor)
}
data<-do.call("rbind",data)
cyclesPull<-sample(data$Cycle,Pulls)
index<-which(data$Cycle %in% cyclesPull)
datasub<-data[sample(index,length(index)),] #randomize index, so when you sort by cycle you don't pure random order
orders<-cbind(unique(datasub$Cycle),1:length(unique(datasub$Cycle)))
datasub$Cycle<-match(datasub$Cycle, orders[,1])
datasub<-datasub[order(datasub$Cycle,datasub$StartDateTime),]
#now convert it to FG format
sf<-getFileName(datasub$Wavefile)
sfdt<-vector(length=length(sf))
#insert a slash
for(n in 1:length(sf)){
lenN<-nchar(sf[n])
sfdt[n]<-substr(sf[n],lenN-16,lenN-4)
#sf[n]<-paste(substr(sf[n],1,lenN-17),"-",sfdt[n],sep="")
}
year<-paste("20",substr(sfdt,1,2),sep="")
month<-substr(sfdt,3,4)
#assemble fg:
out<-data.frame(sf,paste("/",datasub$MooringDeployID,"/",month,"_",year,"/",sep=""),sfdt,0,datasub$MooringDeployID,datasub$StartSecInWav,datasub$EndSecInWav-datasub$StartSecInWav,datasub$MooringSite)
View(out)
colnames(out)<-c("FileName","FullPath","StartTime","Duration","Deployment","SegStart","SegDur","SiteID")
pathsave<-""
#find the file durations
for(i in 1:nrow(out)){
path = paste(SfRoot,"/Waves",out[i,"FullPath"],out[i,"FileName"],sep="")
if(path!=pathsave){
info<-readWave2(path,header = TRUE)
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}else{
out[i,"Duration"]<-round(info$samples/info$sample.rate)
}
}
out
str(out)
write.csv(out,filePath,row.names = FALSE)
write.csv(out,filePath,row.names = FALSE)
args="//161.55.120.117/NMML_AcousticsData/Working_Folders/INSTINCT_cache/Cache/004be6ff1ea2/a21b11 //161.55.120.117/NMML_AcousticsData/Working_Folders/INSTINCT_cache/Cache/004be6ff1ea2 //161.55.120.117/NMML_AcousticsData/Working_Folders/INSTINCT_cache/Cache/004be6ff1ea2/a21b11/acbd5b //161.55.120.117/NMML_AcousticsData/Audio_Data/DecimatedWaves/1024 T"
args<-strsplit(args,split=" ")[[1]]
DETpath <- args[1]
FGpath <-args[2]
Resultpath <- args[3]
dataPath <- args[4]
fillDat <- args[5]
Dets<-read.csv(paste(DETpath,"DETx.csv.gz",sep="/"))
FG<-read.csv(paste(FGpath,"FileGroupFormat.csv.gz",sep="/"))
#mandatory column names
reqCols<-c("StartTime","EndTime","LowFreq","HighFreq","StartFile","EndFile")
if(any(!reqCols %in% colnames(Dets))){
stop("Not a valid DETx object")
}
allFiles<-unique(c(Dets$StartFile,Dets$EndFile))
FGfull<-FG
FG<-FG[which(!duplicated(FG$FileName)),]
#if true, populate Dets for every file in FG which is not already present
if(fillDat=="T"){
if(any(!FGfull$FileName %in% allFiles)){
files<-FGfull$FileName[!FGfull$FileName %in% allFiles]
rows<-foreach(n=1:length(files)) %do% {
row<-c(0,0.1,0,0,files[n],files[n],NA,"Placeholder",NA)
return(row)
}
placeHolderRows<-data.frame(do.call("rbind",rows))
if(nrow(placeHolderRows)>0){
placeHolderRows<-formatToDets(placeHolderRows,Dets)
Dets<-rbind(Dets,placeHolderRows)
}
allFiles<-unique(c(Dets$StartFile,Dets$EndFile))
}
}
MethodID<-"rv-simple-w-metadata-v1-2"
#add argument for placeholder detections to be inserted to see every soundFile. Need it when formatting for GT, may not need it for browsing detections.
#make formatToDets function to let this be general to either placeholder or not considered types.
library(foreach)
formatToDets<-function(data,data2){
colnames(data)[1:6]<-reqCols
colnames(data)[7]<-'label'
colnames(data)[8]<-'SignalCode'
colnames(data)[9]<-'Type'
dropCols<-c("label","SignalCode","Type") #drops any that aren't present in Dets
if(any(!colnames(Dets) %in% dropCols)){
dropColsDo<-dropCols %in% colnames(Dets)
data<-data[,which(!colnames(data) %in% dropCols[!dropColsDo])]
}
data$StartTime<-as.numeric(data$StartTime)
data$EndTime<-as.numeric(data$EndTime)
data$LowFreq<-as.numeric(data$LowFreq)
data$HighFreq<-as.numeric(data$HighFreq)
#add dummy cols to outNeg to match Dets
if(length(colnames(data2))>length(colnames(data))){
addCols<-colnames(data2)[!(colnames(data2) %in% colnames(data))]
dummy<-data.frame(addCols)
colnames(dummy)<-addCols
dummy[,]<-NA
data<-cbind(data,dummy)
}
return(data)
}
#if true, populate Dets for every file in FG which is not already present
if(fillDat=="T"){
if(any(!FGfull$FileName %in% allFiles)){
files<-FGfull$FileName[!FGfull$FileName %in% allFiles]
rows<-foreach(n=1:length(files)) %do% {
row<-c(0,0.1,0,0,files[n],files[n],NA,"Placeholder",NA)
return(row)
}
placeHolderRows<-data.frame(do.call("rbind",rows))
if(nrow(placeHolderRows)>0){
placeHolderRows<-formatToDets(placeHolderRows,Dets)
Dets<-rbind(Dets,placeHolderRows)
}
allFiles<-unique(c(Dets$StartFile,Dets$EndFile))
}
}
colnames(FG)[which(colnames(FG)=="FileName")]<-"StartFile"
FG$StartTime<-NULL
FG$cumsum=c(0,cumsum(FG$Duration)[1:(nrow(FG)-1)])
outNeg<-foreach(i=1:length(allFiles)) %do% {
segs<-FGfull[which(FGfull$FileName==allFiles[i]),]
segVec<-c(segs$SegStart[1],segs$SegStart[1]+segs$SegDur[1])
if(nrow(segs)>1){
for(p in 2:nrow(segs)){
segVec<-c(segVec,segs$SegStart[p],segs$SegStart[p]+segs$SegDur[p])
}
}
segVec<-c(0,segVec,segs$Duration[1])
segVec<-segVec[which(!(duplicated(segVec)|duplicated(segVec,fromLast = TRUE)))]
if(length(segVec)>0){
outs<-foreach(f=seq(1,length(segVec),2)) %do% {
segsRow<-c(segVec[f],segVec[f+1],0,5000,segs$FileName[1],segs$FileName[1],NA,"Not Considered",NA)
return(segsRow)
}
outs<-do.call("rbind",outs)
}else{
outs<-NULL
}
return(outs)
#chop up by 2s, write as negative space and rbind to outputs.
}
outNeg<-do.call("rbind",outNeg)
outNeg<-data.frame(outNeg)
if(nrow(outNeg)>0){
outNeg<-formatToDets(outNeg,Dets)
Dets<-rbind(Dets,outNeg)
}
DetsFG<-merge(Dets,FG,by="StartFile")
DetsFGSameFile <-DetsFG[which(DetsFG$StartFile==DetsFG$EndFile),]
DetsFGdiffFile <-DetsFG[which(!DetsFG$StartFile==DetsFG$EndFile),]
#for same time, just end - start
DetsFGSameFile$DeltaTime<-DetsFGSameFile$EndTime-DetsFGSameFile$StartTime
DetsFGdiffFile$DeltaTime<-(DetsFGdiffFile$Duration-DetsFGdiffFile$StartTime)+DetsFGdiffFile$EndTime
DetsFG<-rbind(DetsFGSameFile,DetsFGdiffFile)
DetsFG<-DetsFG[order(DetsFG$StartFile,DetsFG$StartTime),]
DetsFG$FileOffset<-DetsFG$StartTime
#Raven friendly start and end times.
DetsFG$StartTime<-DetsFG$FileOffset+DetsFG$cumsum
DetsFG$EndTime<-DetsFG$StartTime+DetsFG$DeltaTime
colnames(FG)[which(colnames(FG)=="StartFile")]<-"EndFile"
EFFP<-merge(Dets,FG,by="EndFile")
EFFP<-EFFP[order(EFFP$StartFile,EFFP$StartTime),]
if(nrow(DetsFG)>=1){
DetsFG$StartFile<-paste(dataPath,DetsFG$FullPath,DetsFG$StartFile,sep="")
DetsFG$EndFile<-paste(dataPath,EFFP$FullPath,DetsFG$EndFile,sep="")
}
#strike several metadata fields
dropCols<-c("DiffTime","FullPath","Deployment","SiteID","cumsum","Duration","SegStart","SegDur")
DetsFG<-DetsFG[,which(!colnames(DetsFG) %in% dropCols)]
keepCols<-c("StartTime","EndTime","LowFreq","HighFreq","StartFile","EndFile","FileOffset","DeltaTime")
DetsFGxtra<-data.frame(DetsFG[,which(!colnames(DetsFG) %in% keepCols)])
colnames(DetsFGxtra)<-colnames(DetsFG)[which(!colnames(DetsFG) %in% keepCols)]
if(nrow(DetsFG)>=1){
out<-data.frame(1:nrow(DetsFG),"Spectrogram 1",1,DetsFG$StartTime,DetsFG$EndTime,DetsFG$LowFreq,DetsFG$HighFreq,DetsFG$StartFile,
DetsFG$EndFile,DetsFG$FileOffset,DetsFG$DeltaTime,DetsFGxtra)
}else{
out<-data.frame(matrix(ncol = 11+length(DetsFGxtra), nrow = 0))
if(length(DetsFGxtra)>0){
colnames(out)[12:(11+length(DetsFGxtra))]<-names(DetsFGxtra)
}
}
colnames(out)[1:11]<-c("Selection","View","Channel","Begin Time (s)","End Time (s)","Low Freq (Hz)","High Freq (Hz)",
"Begin Path","End Path","File Offset (s)","Delta Time (s)")
out
Resultpath
